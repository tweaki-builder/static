name: Clone Website

on:
  workflow_dispatch:
    inputs:
      url:
        description: 'URL to clone (must include protocol, e.g. https://example.com)'
        required: true
        type: string
      directory:
        description: 'Output folder name inside the repo (e.g. my-cloned-site)'
        required: true
        type: string
        default: cloned-site

jobs:
  clone:
    runs-on: ubuntu-latest
    permissions:
      contents: write    # Needed if you want to commit results back (optional)
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'   # Caches node_modules automatically

      - name: Cache Puppeteer Chromium
        id: cache-puppeteer
        uses: actions/cache@v4
        with:
          path: ~/.cache/puppeteer
          key: puppeteer-${{ runner.os }}-v3-${{ hashFiles('**/package-lock.json') }}
          restore-keys: |
            puppeteer-${{ runner.os }}-v3-

      - name: Install dependencies
        run: |
          npm ci || npm install website-scraper website-scraper-puppeteer

      - name: Create/Update package.json (if missing or incomplete)
        run: |
          if [ ! -f package.json ]; then
            npm init -y
          fi
          npm install website-scraper website-scraper-puppeteer --save

      - name: Create cloning script
        run: |
          cat > index.js << 'EOF'
          const scrape = require('website-scraper').default;
          const PuppeteerPlugin = require('website-scraper-puppeteer').default;
          const path = require('path');

          (async () => {
            const url = process.argv[2];
            const dir = process.argv[3];

            if (!url || !dir) {
              console.error('‚ùå Usage: node index.js <url> <directory>');
              process.exit(1);
            }

            try {
              console.log(`üîÑ Cloning ${url} into ${dir}...`);
              await scrape({
                urls: [url],
                directory: path.resolve(__dirname, dir),
                recursive: true,
                maxDepth: 10,
                plugins: [
                  new PuppeteerPlugin({
                    launchOptions: { 
                      headless: true,
                      args: ['--no-sandbox', '--disable-setuid-sandbox']
                    },
                    scrollToBottom: { timeout: 15000, viewportN: 10 },
                    blockNavigation: false
                  })
                ],
                sources: [
                  { selector: 'img', attr: 'src' },
                  { selector: 'link[rel="stylesheet"]', attr: 'href' },
                  { selector: 'script', attr: 'src' },
                  { selector: 'source', attr: 'srcset' }
                ]
              });
              console.log('‚úÖ Website cloned successfully!');
            } catch (err) {
              console.error('‚ùå Cloning failed:', err.message || err);
              process.exit(1);
            }
          })();
          EOF

      - name: Run website cloning
        env:
          INPUT_URL: ${{ inputs.url }}
          OUTPUT_DIR: ${{ inputs.directory }}
        run: |
          node index.js "$INPUT_URL" "$OUTPUT_DIR"

      - name: Upload cloned website as artifact
        uses: actions/upload-artifact@v4
        with:
          name: ${{ inputs.directory }}
          path: ${{ inputs.directory }}
          retention-days: 7

      # Optional: Commit and push the cloned files back to repo
      # Uncomment if you want the cloned site permanently stored in repo
      # - name: Commit and push cloned site
      #   run: |
      #     git config user.name "github-actions[bot]"
      #     git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
      #     git add ${{ inputs.directory }} || echo "Nothing to add"
      #     git commit -m "Auto-clone: ${{ inputs.url }}" || echo "Nothing to commit"
      #     git push || echo "Nothing to push"
