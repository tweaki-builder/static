name: Clone Website
on:
  workflow_dispatch:
    inputs:
      url:
        description: 'URL to clone (e.g., https://html.awaikenthemes.com/inspaire/index.html)'
        required: true
        type: string
      directory:
        description: 'Output folder name (e.g., inspaire-clone)'
        required: true
        type: string
        default: cloned-site

jobs:
  clone-and-push:
    runs-on: ubuntu-latest
    permissions:
      contents: write  # Required for pushing with GITHUB_TOKEN
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for safe pushing

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '24'

      - name: Install dependencies
        run: |
          npm init -y
          npm install website-scraper website-scraper-puppeteer

      - name: Create cloning script
        run: |
          cat > index.js << 'EOF'
          const scrape = require('website-scraper').default;
          const PuppeteerPlugin = require('website-scraper-puppeteer').default;
          const path = require('path');
          const fs = require('fs');

          (async () => {
            const url = process.argv[2];
            const dirName = process.argv[3];

            if (!url || !dirName) {
              console.error('‚ùå Usage: node index.js <url> <directory>');
              process.exit(1);
            }

            const directory = path.resolve(__dirname, dirName);

            // Remove existing folder if it exists
            if (fs.existsSync(directory)) {
              console.log(`üóëÔ∏è Removing existing folder '${dirName}'...`);
              fs.rmSync(directory, { recursive: true, force: true });
            }

            try {
              console.log(`üîÑ Cloning ${url} into folder '${dirName}' ...`);

              await scrape({
                urls: [url],
                directory: directory,
                plugins: [
                  new PuppeteerPlugin({
                    launchOptions: {
                      headless: true,
                      args: ['--no-sandbox', '--disable-setuid-sandbox', '--disable-web-security']
                    },
                    gotoOptions: {
                      waitUntil: 'networkidle0',  // Wait until no network activity
                      timeout: 60000
                    },
                    scrollToBottom: {
                      timeout: 30000,   // Longer timeout for scrolling
                      viewportN: 20     // Scroll multiple times to trigger lazy-load
                    },
                    renderOptions: async (page) => {
                      // Disable CSS animations and transitions for instant final state
                      await page.addStyleTag({
                        content: `
                          *, *::before, *::after {
                            transition: none !important;
                            transition-duration: 0s !important;
                            transition-delay: 0s !important;
                            animation: none !important;
                            animation-duration: 0s !important;
                            animation-delay: 0s !important;
                          }
                        `
                      });

                      // Optional: Force images to load (bypass lazy-loading)
                      await page.evaluate(() => {
                        document.querySelectorAll('img[loading="lazy"]').forEach(img => {
                          img.loading = 'eager';
                          if (img.dataset.src) img.src = img.dataset.src;
                          if (img.dataset.srcset) img.srcset = img.dataset.srcset;
                        });
                      });

                      // Extra delay to allow any remaining JS/timers to finish
                      await page.waitForTimeout(15000);  // 15 seconds - adjust if needed (10000-30000)
                    }
                  })
                ]
              });

              console.log('‚úÖ Website cloned successfully!');
            } catch (err) {
              console.error('‚ùå Cloning failed:', err.message || err);
              process.exit(1);
            }
          })();
          EOF

      - name: Run cloning script
        env:
          INPUT_URL: ${{ inputs.url }}
          OUTPUT_DIR: ${{ inputs.directory }}
        run: |
          node index.js "$INPUT_URL" "$OUTPUT_DIR"

      - name: Commit and push cloned folder to main branch
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          
          git add "${{ inputs.directory }}"
          git commit -m "Add cloned site: ${{ inputs.directory }} from ${{ inputs.url }}" || echo "No changes to commit"
          git push origin HEAD:main
